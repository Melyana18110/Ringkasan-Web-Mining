<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="None">
        
        <link rel="canonical" href="https://example.com/">
        <link rel="shortcut icon" href="img/favicon.ico">
        <title>My Docs</title>
        <link href="css/bootstrap.min.css" rel="stylesheet">
        <link href="css/font-awesome.min.css" rel="stylesheet">
        <link href="css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css">

        <script src="js/jquery-1.10.2.min.js" defer></script>
        <script src="js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body class="homepage">
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href=".">My Docs</a>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#ringkasan-web-mining" class="nav-link">Ringkasan Web Mining</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#crawling" class="nav-link">CRAWLING</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#preprocessing" class="nav-link">PREPROCESSING</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#modelling" class="nav-link">MODELLING</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#evaluasi" class="nav-link">EVALUASI</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="ringkasan-web-mining">Ringkasan Web Mining</h1>
<h4 id="melyana-febrianti-180411100110">Melyana Febrianti / 180411100110</h4>
<h2 id="crawling">CRAWLING</h2>
<p>Crawling adalah teknik pengumpulan data yang digunakan untuk mengindeks informasi pada halaman menggunakan URL (Uniform Resource Locator) dengan menyertakan API (Application Programming Interface) untuk melakukan penambangan dataset yang lebih besar dan data yang dapat dikumpulkan berupa artikel, lembar produk, video, gambar, link, dan lain-lain. Mesin pencarian menggunakan alat yang disebut sebagai crawler untuk memutuskan situs web mana yang akan dipindai.
Tindakan ini sangat penting untuk melakukan strategi Search Engine Optimization karena ini adalah momen ketika mesin pencari menemukan jumlah dan kualitas koneksi pada suatu halaman. Setiap kali crawler mengunjungi halaman situs web, mereka akan melihat melalui Document Model Object yang merupakan kode HTML dan Javascript yang telah dirender dari halaman situs dan bisa dilihat crawler untuk menemukan link ke halaman lain. Sehingga memungkinkan mesin pencarian untuk menemukan halaman baru di situs web dan setiap link baru tersebut akan dimuat ke dalam antrean yang akan dikunjungi crawler di lain waktu. (Apa itu Crawling, Patrick Trusto J W, 21 Oktober 2020)</p>
<p><strong>Tujuan Crawling</strong></p>
<ol>
<li>Dapat melihat data perbandingan harga</li>
<li>Menunjang web analysis tool seperti menganalisis suatu web untuk mengetahui page view, backlink, internal link, dan lain-lain</li>
<li>Menunjang data mining seperti mengumpulkan set data dari sumber terbuka di internet</li>
</ol>
<p><strong>Langkah-Langkah Crawling</strong></p>
<ol>
<li>Mengunjungi sebuah situs dan berbagai link URL yang terdapat dalam laman</li>
<li>Menemukan atau mencari halaman web yang penting</li>
<li>Melakukan kunjungan ulang ke setiap web page untuk memeriksa update</li>
<li>Mengikuti protokol robot.txt yang berisi aturan tertentu mengenai akses bot pada suatu web</li>
</ol>
<p><strong>Contoh Code Crawling</strong></p>
<ol>
<li>
<p>Install scrapy pada Command Prompt ketik "pip install scrapy"</p>
</li>
<li>
<p>Mencari link yang akan di gunakan atau yang akan di crawl (https://niion.co/collections/niion-basic)</p>
</li>
<li>
<p>Buat folder baru lalu pergi ke Command Prompt E:\Web Mining\Tugas 1&gt;scrapy startproject niion</p>
</li>
<li>
<p>Setelah proses tersebut selesai lanjutkan E:\Web Mining\Tugas 1&gt;cd niion dan E:\Web Mining\Tugas 1\niion&gt;scrapy genspider tasniion https://niion.co/collections/niion-basic</p>
</li>
<li>
<p>Buka file tasniion.py tuliskan folder seperti dibawah ini:</p>
</li>
</ol>
<p>```python
   import scrapy
   class TasniionSpider(scrapy.Spider):
       name = 'tasniion'
       allowed_domains = ['https://niion.co/collections/niion-basic']
       start_urls = ['https://niion.co/collections/niion-basic/']</p>
<pre><code>   def parse(self, response):
       batas = response.css ('.product-card')

       for item in batas:
           nama = item.css('.product-card__name::text').extract()
           harga = item.css('.money::text').extract()

           yield{
               'nama' : nama,
               'harga' : harga,
           }
</code></pre>
<p>```</p>
<ol>
<li>Buka kembali Command Prompt E:\Web Mining\Tugas 1\niion&gt;scrapy crawl tasniion, maka hasilnya akan menampilkan nama dan harga dari produk yang terdapat pada link yang telah digunakan:</li>
</ol>
<p><code>python
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['DUFFLE V.2'], 'harga': ['IDR 199.000']}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['LUNAR URBAN BLACK'], 'harga': ['IDR 169.000']}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['LUNAR URBAN MAROON'], 'harga': ['IDR 169.000']}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['LUNAR URBAN NAVY'], 'harga': ['IDR 169.000']}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['LUNAR URBAN YELLOW'], 'harga': []}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['LUNAR URBAN MAGENTA'], 'harga': ['IDR 169.000']}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['LUNAR URBAN LIGHT GREY'], 'harga': ['IDR 169.000']}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['NUI RED'], 'harga': []}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['PO HIPBAG BLACK (ETA 30 JUNI 2021)'], 'harga': ['IDR 189.000', 'IDR 118.300']}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['WAISTER NAVY BLUE'], 'harga': ['IDR 189.000']}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['WAISTER DARK GREY'], 'harga': ['IDR 189.000']}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['HIPBAG CAMO DARK BROWN'], 'harga': ['IDR 189.000']}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['HIPBAG CAMO NAVY'], 'harga': ['IDR 189.000']}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['LUNAR RUNNING LIGHT BLUE'], 'harga': ['IDR 129.000']}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['LUNAR RUNNING RED'], 'harga': ['IDR 129.000']}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['HIPBAG CAMO GREY'], 'harga': ['IDR 189.000']}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['NUI LIGHT BLUE'], 'harga': []}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['LUNAR RUNNING ROYAL PURPLE'], 'harga': ['IDR 129.000']}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['LUNAR RUNNING MEDIUM BLUE'], 'harga': ['IDR 129.000']}
   2021-06-10 16:10:08 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://niion.co/collections/niion-basic/&gt;
   {'nama': ['HIPBAG RED'], 'harga': ['IDR 189.000']}</code></p>
<ol>
<li>Jika ingin dijadikan file excel maka pada Command Prompt E:\Web Mining\Tugas 1\niion&gt;scrapy crawl tasniion -o tasniion.csv</li>
</ol>
<h2 id="preprocessing">PREPROCESSING</h2>
<p>Preprocessing merupakan salah satu tahapan yang penting untuk data pada proses mining. Terkadang pada data tersebut terdapat berbagai permasalahan yang dapat mengganGgu hasil dari proses mining contohnya seperi missing value, data redundant, outliers, ataupun format data yang tidak sesuai dengan sistem. Preprocessing merupakan salah satu tahapan menghilangkan permasalahan-permasalahan yang dapat mengganggu hasil daripada proses data. Saat klasifikasi dokumen yang menggunakan data bertipe teks, terdapat beberapa macam proses yang dilakukan diantaranya case folding, filtering(remove punctution), stopword removal, stemming, tokenization dan sebagainya. (Apa itu Preprocessing, Samir, 23 June 2019)</p>
<p><strong>Tujuan Preprocessing</strong></p>
<ol>
<li>Pembersihan data</li>
<li>Integrasi data</li>
<li>Transformasi data</li>
<li>Pengurangan data</li>
<li>Diskretisasi data</li>
</ol>
<p><strong>Langkah-Langkah Preprocessing</strong></p>
<ol>
<li>Memiliki data dokumen untuk di proses</li>
<li>Cleaning data dengan menghilangkan tanda baca atau karakter lain selain teks dengan fungsi punctuation removal</li>
<li>Case folding proses untuk mengubah setiap kata menjadi sama, contoh semua kata berhuruf kecil menggunakan fungsi lowercase</li>
<li>Stopword removal proses untuk menghapus kata-kata yang terlalu umum dan tidak penting</li>
<li>Stemming proses untuk mengubah kata pada setiap kalimat ke bentuk dasar (menghapus kata imbuhan)</li>
<li>Tokenizing proses untuk memenggal setiap kata dalam kalimat termasuk karakter</li>
</ol>
<p><strong>Contoh Code Preprocessing</strong></p>
<pre><code class="language-python">import numpy as np
import doctest
import sys
from IPython.display import Image
from requests_html import HTMLSession

import matplotlib.pyplot as plt
import networkx as nx
from nltk.tokenize.punkt import PunktSentenceTokenizer
from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer

session = HTMLSession()

#use session to get the page
r = session.get('https://www.jawapos.com/hijrah-ramadan/21/04/2021/salat-tarawih-di-masjid-3-hari-ramadan-dan-itikaf-10-hari-terakhir/')

artikel = r.html.find('div.content')

for item in artikel:
    newsitem = item.find('div.content', first=True)
    berita = newsitem.text
    print(berita)
    print(&quot;&quot;)

doc_tokenizer = PunktSentenceTokenizer()
sentences_list = doc_tokenizer.tokenize(berita)

import string 
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory# create stemmer
factory = StemmerFactory()
stemmer = factory.create_stemmer()

import re # impor modul regular expressionkalimat = &quot;Berikut ini adalah 5 negara dengan pendidikan terbaik di dunia adalah Korea Selatan, Jepang, Singapura, Hong Kong, dan Finlandia.&quot;
dokumenre=[]
for i in sentences_list:
    hasil = re.sub(r&quot;\d+&quot;, &quot;&quot;, i)
    dokumenre.append(hasil) 

dokumen=[]
for i in dokumenre:
    hasil =  i.replace('\n','') 
    dokumen.append(hasil) 

from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory
from nltk.tokenize import word_tokenize
factory = StopWordRemoverFactory()
stopword  = factory.create_stop_word_remover()
#a=cv_matrix.toarray()
a=len(dokumen)
dokumenstop=[]
for i in range(0, a):
    sentence = stopword.remove(dokumen[i])
    dokumenstop.append(sentence)

cv = CountVectorizer()
cv_matrix = cv.fit_transform(dokumen)
a=cv_matrix.toarray()

from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory
from nltk.tokenize import word_tokenize
factory = StopWordRemoverFactory()
dokumenstop=[]
for i in dokumen:
    output = i.translate(str.maketrans(&quot;&quot;,&quot;&quot;,string.punctuation))
    dokumenstop.append(output)

factory = StemmerFactory()
stemmer = factory.create_stemmer()
dokumenstem=[]
for i in dokumenstop:
    output = stemmer.stem(i)
    dokumenstem.append(output)

bag = cv.fit_transform(dokumenstem)

print(cv.get_feature_names())

</code></pre>
<p>Outputnya sebagai berikut:</p>
<pre><code class="language-python">JawaPos.com – Umat Islam diwajibkan berpuasa selama bulan Ramadan. Untuk menambah pahala dan nilai ibadah, umat Islam juga diminta menunaikan ibadah salat Tarawih, hukumnya sunat muakad atau sunat yang dikuatkan. Namun, jika ingin meneladani kebiasaan Nabi Muhammad SAW, ternyata beliau menunaikan salat Tarawih di masjid bukan sepanjang malam selama 30 hari Ramadan.
Imam Besar Masjid Cut Meutia Ustad Mahfud Mustofa mengatakan sebuah riwayat menyebutkan kalau Nabi Muhammad SAW tidak salat tarawih sebulan penuh dengan berjamaah di masjid ketika bulan Puasa atau Ramadan. Bahkan Rasulullah hanya tiga malam saja ke masjid.
“Memang itikaf di masjid yang terbaik itu peristiwa pada 10 malam terakhir pada saat Ramadan. Namun untuk Tarawih, Nabi itu melakukannya 3 hari pertama malam Ramadan,” kata Ustad Mustofa kepada JawaPos.com baru-baru ini.
Nabi Muhammad SAW memilih salat tarawih di rumah setelah tiga malam tersebut. Hal itu karena jamaah Nabi tumpah ruah dan penuh sesak pada malam ketiga. Maka saat hari keempat, Nabi memilih salat Tarawih di rumah.
Mengapa demikian? Menurutnya, hal itu dimaksudkan agar umat Muslim tidak berpikir untuk menjadikan salat Tarawih adalah ibadah wajib.
“Apa maksudnya? Supaya membedakan kalau nabi yang melakukan takutnya salat Tarawih itu jadi wajib hukumnya,” tegasnya.
Selain salat Tarawih, Ustad Mustofa menganjurkan ibadah lainnya yang juga bisa memperbanyak pahala. Salah satunya adalah membantu orang tua serta bertadarus Al Quran. Maka pahala seseorang akan dilipatgandakan.
Saksikan video menarik berikut ini:

['adalah', 'agar', 'akan', 'akhir', 'al', 'anjur', 'apa', 'atau', 'bahkan', 'baik', 'bantu', 'banyak', 'barubaru', 'beda', 'beliau', 'besar', 'biasa', 'bisa', 'buah', 'bukan', 'bulan', 'cut', 'dan', 'demikian', 'dengan', 'di', 'dilipatgandakan', 'empat', 'hal', 'hanya', 'hari', 'hukum', 'ibadah', 'ikut', 'imam', 'ingin', 'ini', 'islam', 'itikaf', 'itu', 'jadi', 'jamaah', 'jawaposcom', 'jika', 'juga', 'kalau', 'karena', 'kata', 'ke', 'kepada', 'ketika', 'kuat', 'lain', 'laku', 'lama', 'mahfud', 'maka', 'maksud', 'malam', 'masjid', 'memang', 'mengapa', 'meutia', 'minta', 'muakad', 'muhammad', 'muslim', 'mustofa', 'nabi', 'namun', 'nilai', 'nyata', 'orang', 'pada', 'pahala', 'panjang', 'penuh', 'peristiwa', 'pertama', 'pikir', 'pilih', 'puasa', 'quran', 'ramadan', 'rasulullah', 'riwayat', 'ruah', 'rumah', 'saat', 'saja', 'saksi', 'salah', 'salat', 'satu', 'saw', 'sebut', 'selain', 'serta', 'sesak', 'sunat', 'supaya', 'tadarus', 'takut', 'tambah', 'tarawih', 'tarik', 'tegas', 'teladan', 'telah', 'tidak', 'tiga', 'tua', 'tumpah', 'tunai', 'turut', 'umat', 'untuk', 'ustad', 'video', 'wajib', 'yang']
</code></pre>
<h2 id="modelling">MODELLING</h2>
<p>Modelling Data adalah metode yang digunakan untuk menentukan dan menganalisis persyaratan data yang diperlukan untuk mendukung proses bisnis suatu organisasi. Pemodelan data bisa diartikan juga sebagai proses yang digunakan untuk mendefinisikan dan menganalisis persyaratan data yang diperlukan untuk mendukung proses bisnis dalam lingkup sistem informasi yang sesuai dalam organisasi. Persyaratan data yang pada awalnya dicatat sebagai model data konseptual yang pada dasarnya satu set spesifikasi teknologi independen tentang data dan digunakan untuk mendiskusikan kebutuhan awal dengan para pemangku kepentingan bisnis. Langkah terakhir dalam pemodelan data adalah mengubah model data logis untuk model data fisik yang mengatur data ke dalam tabel, dan rekening untuk rincian akses, kinerja dan penyimpanan. (Pengertian Data Modelling, Rifqi Mulyawan, 13 Juni 2019)</p>
<p><strong>Tujuan Preprocessing</strong></p>
<ol>
<li>Memastikan bahwa semua objek data yang dibutuhkan oleh database diwakili secara akurat</li>
<li>Membantu merancang basis data pada tingkat konseptual, fisik, dan logis</li>
<li>Membantu menentukan tabel relasional</li>
<li>Memberikan gambaran yang jelas tentang data dasar</li>
<li>Dapat mengidentifikasi data yang hilang dan berlebihan</li>
<li>Pemeliharaan infrastuctural Information Technology (IT) dapat menjadi lebih murah dan lebih cepat cara kerjanya</li>
</ol>
<p><strong>Langkah-Langkah Modelling</strong></p>
<ol>
<li>Mengidentifikasi jenis entitas</li>
<li>Mengidentifikasi atribut</li>
<li>Menerapkan konvensi penamaan</li>
<li>Mengidentifikasi hubungan</li>
<li>Menerapkan pola model data</li>
<li>Menetapkan kunci</li>
<li>Melakukan normalisasi untuk mengurangi redundansi data</li>
<li>Mendinormalisasinya untuk meningkatkan kinerja</li>
</ol>
<p><strong>Contoh Code Modelling</strong></p>
<pre><code class="language-python">from sklearn import tree
from sklearn import svm
from sklearn import neighbors
from sklearn.metrics import accuracy_score
from sklearn.naive_bayes import GaussianNB

cDT = tree.DecisionTreeClassifier()
cSVM = svm.SVC()
cKNN = neighbors.KNeighborsClassifier()
cNB = GaussianNB()

# [tingi, berat, ukuran_sepatu]
X = [[181, 80, 44], [177, 70, 43], [160, 60, 38], [154, 54, 37], [166, 65, 40],
 [190, 90, 47], [175, 64, 39], [177, 70, 40], [159, 55, 37], [171, 75, 42],
 [181, 85, 43]]

Y = ['pria', 'pria', 'wanita', 'wanita', 'pria', 'pria', 'wanita', 'wanita',
 'wanita', 'pria', 'pria']

cDT = cDT.fit(X, Y)
cSVM = cSVM.fit(X, Y)
cKNN = cKNN.fit(X, Y)
cNB = cNB.fit(X, Y)

# data test
X_test = [[198, 92, 48], [184, 84, 44], [183, 83, 44], [166, 47, 36],
 [170, 60, 38], [172, 64, 39], [182, 80, 42], [180, 80, 43]]
Y_test = ['pria', 'pria', 'pria', 'wanita', 'wanita', 'wanita', 'pria', 'pria']

# prediksi data test
Y_DT = cDT.predict(X_test)
Y_SVM = cSVM.predict(X_test)
Y_KNN = cKNN.predict(X_test)
Y_NB = cNB.predict(X_test)

# print prediksi
print(&quot;Prediksi Decision Tree : &quot;, Y_DT)
print(&quot;Prediksi SVM : &quot;, Y_SVM)
print(&quot;Prediksi KNN : &quot;, Y_KNN)
print(&quot;Prediksi Naive Bayes : &quot;, Y_NB)

# print akurasi
print(&quot;Akurasi Decision Tree : &quot;, accuracy_score(Y_test, Y_DT))
print(&quot;Akurasi SVM : &quot;, accuracy_score(Y_test, Y_SVM))
print(&quot;Akurasi KNN : &quot;, accuracy_score(Y_test, Y_KNN))
print(&quot;Akurasi Naive Bayes : &quot;, accuracy_score(Y_test, Y_NB))

</code></pre>
<p>Outputnya sebagai berikut:</p>
<pre><code class="language-python">Prediksi Decision Tree :  ['pria' 'pria' 'pria' 'wanita' 'wanita' 'wanita' 'pria' 'pria']
Prediksi SVM :  ['pria' 'pria' 'pria' 'pria' 'pria' 'pria' 'pria' 'pria']
Prediksi KNN :  ['pria' 'pria' 'pria' 'wanita' 'wanita' 'pria' 'pria' 'pria']
Prediksi Naive Bayes :  ['pria' 'pria' 'pria' 'wanita' 'wanita' 'wanita' 'pria' 'pria']
Akurasi Decision Tree :  1.0
Akurasi SVM :  0.625
Akurasi KNN :  0.875
Akurasi Naive Bayes :  1.0
</code></pre>
<h2 id="evaluasi">EVALUASI</h2>
<p>Evaluasi merupakan pengukuran dan perbaikan suatu data, contohnya membandingkan hasil data dan menganalisisnya serta proses menentukan nilai berdasarkan acuan tertentu untuk mencapai tujuan yang diinginkan. Evaluasi diadakan untuk mengumpulkan dan mengombinasikan data dengan standar tujuan yang hendak dicapai sehingga dapat dijadikan dasar dalam pengambilan keputusan. Dan hasil dari evaluasi tersebut akan digunakan sebagai analisis program selanjutnya</p>
<p><strong>Tujuan Evaluasi</strong></p>
<ol>
<li>Berperan sebagai umpan balik untuk melakukan perbaikan pada suatu data sehingga bisa dijadikan acuan dalam data berikutnya</li>
<li>Mengetahui kelebihan dan kekurangan pada data tersebut</li>
<li>Memahami tingkat keefektifan suatu data</li>
<li>Mengukur keberhasilan suatu data</li>
</ol>
<p><strong>Langkah-Langkah Evaluasi</strong></p>
<ol>
<li>Memaparkan dengan jelas poin penting apa yang akan di evaluasi</li>
<li>Merancang kegiatan evaluasi</li>
<li>Pengumpulan data evaluasi</li>
<li>Analisis data dan pengolahannya</li>
<li>Pelaporan hasil evaluasi </li>
</ol>
<p><strong>Contoh Code Evaluasi</strong></p>
<pre><code class="language-python">import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.preprocessing import LabelEncoder
from sklearn.svm import SVC

np.random.seed(123)
data = pd.read_csv('data.csv')
data = data.iloc[:,1:-1]  #remove kolom id
label_encoder = LabelEncoder()
data.iloc[:,0] = label_encoder.fit_transform(data.iloc[:,0]).astype('float64') #mengubah value diagnosis menjadi 1 dan 0

paramater = data.iloc[:,1:-1]
target = data.iloc[:,0]

#menghitung correlation
corr_matrix = paramater.corr().abs()
#ambil matrix segitiga atas
upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))

#temukan feature dengan correlation diatas 0.9
to_drop = [column for column in upper.columns if any(upper[column] &gt; 0.9)]
for ls in to_drop:
    paramater=paramater.drop([ls],axis=1)
x_train, x_test, y_train, y_test = train_test_split(paramater.values, target.values, test_size = 0.2)
svc = SVC() # The default kernel adalah gaussian kernel
svc.fit(x_train, y_train)                        
prediction = svc.predict(x_test)     
print(&quot;Akurasi:&quot;,metrics.accuracy_score(y_test, prediction))
</code></pre>
<p>Outputnya sebagai berikut:</p>
<pre><code class="language-python">Akurasi: 0.9473684210526315
</code></pre></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = ".",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="js/base.js" defer></script>
        <script src="search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>

<!--
MkDocs version : 1.2
Build Date UTC : 2021-06-10 11:19:52.501889+00:00
-->
